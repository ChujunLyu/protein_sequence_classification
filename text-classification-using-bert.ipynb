{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013649,
     "end_time": "2021-11-12T11:24:53.008507",
     "exception": false,
     "start_time": "2021-11-12T11:24:52.994858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Import Libraries and Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-12T11:24:53.039154Z",
     "iopub.status.busy": "2021-11-12T11:24:53.038641Z",
     "iopub.status.idle": "2021-11-12T11:24:53.050071Z",
     "shell.execute_reply": "2021-11-12T11:24:53.049430Z",
     "shell.execute_reply.started": "2021-11-12T11:24:02.008767Z"
    },
    "papermill": {
     "duration": 0.029155,
     "end_time": "2021-11-12T11:24:53.050187",
     "exception": false,
     "start_time": "2021-11-12T11:24:53.021032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset/solubility_dev.csv\n",
      "/kaggle/input/dataset/solubility_train.csv\n",
      "/kaggle/input/dataset/solubility_test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:24:53.080765Z",
     "iopub.status.busy": "2021-11-12T11:24:53.079964Z",
     "iopub.status.idle": "2021-11-12T11:24:53.877937Z",
     "shell.execute_reply": "2021-11-12T11:24:53.877271Z",
     "shell.execute_reply.started": "2021-11-12T11:24:02.030070Z"
    },
    "papermill": {
     "duration": 0.814563,
     "end_time": "2021-11-12T11:24:53.878045",
     "exception": false,
     "start_time": "2021-11-12T11:24:53.063482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import BERT tokenization\n",
    "\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:24:53.911966Z",
     "iopub.status.busy": "2021-11-12T11:24:53.910979Z",
     "iopub.status.idle": "2021-11-12T11:25:08.448181Z",
     "shell.execute_reply": "2021-11-12T11:25:08.448717Z",
     "shell.execute_reply.started": "2021-11-12T11:24:03.071409Z"
    },
    "papermill": {
     "duration": 14.557227,
     "end_time": "2021-11-12T11:25:08.448863",
     "exception": false,
     "start_time": "2021-11-12T11:24:53.891636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\r\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 123 kB 937 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.16.31)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.7.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (4.45.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.18.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2.23.0)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2020.4.4)\r\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\r\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.31 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (1.19.31)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.31->boto3->pytorch_pretrained_bert) (2.8.1)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.31->boto3->pytorch_pretrained_bert) (1.25.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.31->boto3->pytorch_pretrained_bert) (1.14.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.31->boto3->pytorch_pretrained_bert) (1.25.9)\r\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.31 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch_pretrained_bert) (1.19.31)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.18.5)\r\n",
      "Installing collected packages: pytorch-pretrained-bert\r\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "!pip install pytorch_pretrained_bert\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:08.485824Z",
     "iopub.status.busy": "2021-11-12T11:25:08.485295Z",
     "iopub.status.idle": "2021-11-12T11:25:09.358924Z",
     "shell.execute_reply": "2021-11-12T11:25:09.357931Z",
     "shell.execute_reply.started": "2021-11-12T11:24:17.914289Z"
    },
    "papermill": {
     "duration": 0.894249,
     "end_time": "2021-11-12T11:25:09.359044",
     "exception": false,
     "start_time": "2021-11-12T11:25:08.464795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/dataset/solubility_train.csv')\n",
    "test_data = pd.read_csv('../input/dataset/solubility_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:09.405822Z",
     "iopub.status.busy": "2021-11-12T11:25:09.404950Z",
     "iopub.status.idle": "2021-11-12T11:25:09.412389Z",
     "shell.execute_reply": "2021-11-12T11:25:09.412819Z",
     "shell.execute_reply.started": "2021-11-12T11:24:18.747128Z"
    },
    "papermill": {
     "duration": 0.03754,
     "end_time": "2021-11-12T11:25:09.412927",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.375387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meta</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psol_train_0</td>\n",
       "      <td>GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Psol_train_1</td>\n",
       "      <td>MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Psol_train_2</td>\n",
       "      <td>MGSDKIHHHHHHMEKSIQDTIHGVIKLEDWMVEIVDTPQFQRLRRI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Psol_train_3</td>\n",
       "      <td>MEKYIHSVEDYHRLISYLENNLNYEDSVVNHVIYVIAKTGMRYGEI...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psol_train_4</td>\n",
       "      <td>MSLTDSFTVRSIEGVCFRYPLATPVVTSFGKMLNRPAVFVRVVDED...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Meta                                           Sequence  Label\n",
       "0  Psol_train_0  GMILKTNLFGHTYQFKSITDVLAKANEEKSGDRLAGVAAESAEERV...      1\n",
       "1  Psol_train_1  MAHHHHHHMSFFRMKRRLNFVVKRGIEELWENSFLDNNVDMKKIEY...      0\n",
       "2  Psol_train_2  MGSDKIHHHHHHMEKSIQDTIHGVIKLEDWMVEIVDTPQFQRLRRI...      0\n",
       "3  Psol_train_3  MEKYIHSVEDYHRLISYLENNLNYEDSVVNHVIYVIAKTGMRYGEI...      0\n",
       "4  Psol_train_4  MSLTDSFTVRSIEGVCFRYPLATPVVTSFGKMLNRPAVFVRVVDED...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01561,
     "end_time": "2021-11-12T11:25:09.444360",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.428750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Label encoding of labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:09.481080Z",
     "iopub.status.busy": "2021-11-12T11:25:09.480250Z",
     "iopub.status.idle": "2021-11-12T11:25:09.488989Z",
     "shell.execute_reply": "2021-11-12T11:25:09.489566Z",
     "shell.execute_reply.started": "2021-11-12T11:24:18.772360Z"
    },
    "papermill": {
     "duration": 0.029732,
     "end_time": "2021-11-12T11:25:09.489708",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.459976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "y = label.fit_transform(train_data['Label'])\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017252,
     "end_time": "2021-11-12T11:25:09.524443",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.507191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build a BERT layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017329,
     "end_time": "2021-11-12T11:25:09.559600",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.542271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we create a BERT embedding layer by importing the BERT model from hub.KerasLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:09.600970Z",
     "iopub.status.busy": "2021-11-12T11:25:09.600238Z",
     "iopub.status.idle": "2021-11-12T11:25:26.159385Z",
     "shell.execute_reply": "2021-11-12T11:25:26.158415Z",
     "shell.execute_reply.started": "2021-11-12T11:24:18.787843Z"
    },
    "papermill": {
     "duration": 16.582018,
     "end_time": "2021-11-12T11:25:26.159510",
     "exception": false,
     "start_time": "2021-11-12T11:25:09.577492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(m_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015876,
     "end_time": "2021-11-12T11:25:26.191589",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.175713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Encoding the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015561,
     "end_time": "2021-11-12T11:25:26.223321",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.207760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase and finally we pass our vocab_file and do_lower_case variables to the Tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:26.264681Z",
     "iopub.status.busy": "2021-11-12T11:25:26.263843Z",
     "iopub.status.idle": "2021-11-12T11:25:26.378089Z",
     "shell.execute_reply": "2021-11-12T11:25:26.377646Z",
     "shell.execute_reply.started": "2021-11-12T11:24:36.433889Z"
    },
    "papermill": {
     "duration": 0.139052,
     "end_time": "2021-11-12T11:25:26.378174",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.239122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=256):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016,
     "end_time": "2021-11-12T11:25:26.410046",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.394046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build The Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015647,
     "end_time": "2021-11-12T11:25:26.441456",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.425809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are all set to create our model. To do so, we will create a function named build_model that having tf.keras.models.Model class. Inside the function we will define our model layers. Our model will consist of three **Dense** neural network layers and also dropout layer. We have chosen a learning rate to 1e-5.\n",
    "\n",
    "**RELU function** :- \n",
    "With default values, this returns max(x, 0), the element-wise maximum of 0 and the input tensor.\n",
    "Modifying default parameters allows you to use non-zero thresholds, change the max value of the activation, and to use a non-zero multiple of the input for values below the threshold.\n",
    "\n",
    "\n",
    "**Softmax function** :-\n",
    "Softmax converts a real vector to a vector of categorical probabilities.\n",
    "The elements of the output vector are in range (0, 1) and sum to 1.\n",
    "Each vector is handled independently. The axis argument sets which axis of the input the function is applied along.\n",
    "Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution.\n",
    "The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)).\n",
    "\n",
    "**Binary corssentropy**:-\n",
    "Computes the cross-entropy loss between true labels and predicted labels.\n",
    "We can use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:26.483897Z",
     "iopub.status.busy": "2021-11-12T11:25:26.483155Z",
     "iopub.status.idle": "2021-11-12T11:25:26.486094Z",
     "shell.execute_reply": "2021-11-12T11:25:26.485620Z",
     "shell.execute_reply.started": "2021-11-12T11:24:36.562437Z"
    },
    "papermill": {
     "duration": 0.028984,
     "end_time": "2021-11-12T11:25:26.486186",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.457202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=254):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    \n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    \n",
    "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    out = tf.keras.layers.Dense(2, activation='softmax')(lay)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T11:25:26.540527Z",
     "iopub.status.busy": "2021-11-12T11:25:26.536130Z",
     "iopub.status.idle": "2021-11-12T12:03:02.058111Z",
     "shell.execute_reply": "2021-11-12T12:03:02.057167Z"
    },
    "papermill": {
     "duration": 2255.556305,
     "end_time": "2021-11-12T12:03:02.058243",
     "exception": false,
     "start_time": "2021-11-12T11:25:26.501938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = 250\n",
    "train_input = bert_encode(train_data.Sequence.values, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test_data.Sequence.values, tokenizer, max_len=max_len)\n",
    "train_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:03:02.096573Z",
     "iopub.status.busy": "2021-11-12T12:03:02.095822Z",
     "iopub.status.idle": "2021-11-12T12:03:02.099262Z",
     "shell.execute_reply": "2021-11-12T12:03:02.099656Z"
    },
    "papermill": {
     "duration": 0.024593,
     "end_time": "2021-11-12T12:03:02.099769",
     "exception": false,
     "start_time": "2021-11-12T12:03:02.075176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "labels = label.classes_\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:03:02.137827Z",
     "iopub.status.busy": "2021-11-12T12:03:02.137066Z",
     "iopub.status.idle": "2021-11-12T12:03:03.156352Z",
     "shell.execute_reply": "2021-11-12T12:03:03.155312Z"
    },
    "papermill": {
     "duration": 1.04045,
     "end_time": "2021-11-12T12:03:03.156514",
     "exception": false,
     "start_time": "2021-11-12T12:03:02.116064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 768)]        0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           49216       tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            66          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,603\n",
      "Trainable params: 109,533,602\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:03:03.197688Z",
     "iopub.status.busy": "2021-11-12T12:03:03.196885Z",
     "iopub.status.idle": "2021-11-12T12:03:03.200726Z",
     "shell.execute_reply": "2021-11-12T12:03:03.200251Z"
    },
    "papermill": {
     "duration": 0.026322,
     "end_time": "2021-11-12T12:03:03.200827",
     "exception": false,
     "start_time": "2021-11-12T12:03:03.174505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01692,
     "end_time": "2021-11-12T12:03:03.235164",
     "exception": false,
     "start_time": "2021-11-12T12:03:03.218244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T12:03:03.277001Z",
     "iopub.status.busy": "2021-11-12T12:03:03.276127Z",
     "iopub.status.idle": "2021-11-12T15:29:19.751944Z",
     "shell.execute_reply": "2021-11-12T15:29:19.751420Z"
    },
    "papermill": {
     "duration": 12376.499362,
     "end_time": "2021-11-12T15:29:19.752052",
     "exception": false,
     "start_time": "2021-11-12T12:03:03.252690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.6217\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66189, saving model to model.h5\n",
      "6248/6248 [==============================] - 1768s 283ms/step - loss: 0.6107 - accuracy: 0.6217 - val_loss: 0.5887 - val_accuracy: 0.6619\n",
      "Epoch 2/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.6776\n",
      "Epoch 00002: val_accuracy improved from 0.66189 to 0.68110, saving model to model.h5\n",
      "6248/6248 [==============================] - 1770s 283ms/step - loss: 0.5752 - accuracy: 0.6776 - val_loss: 0.5616 - val_accuracy: 0.6811\n",
      "Epoch 3/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.6985\n",
      "Epoch 00003: val_accuracy improved from 0.68110 to 0.69518, saving model to model.h5\n",
      "6248/6248 [==============================] - 1764s 282ms/step - loss: 0.5525 - accuracy: 0.6985 - val_loss: 0.5488 - val_accuracy: 0.6952\n",
      "Epoch 4/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7182\n",
      "Epoch 00004: val_accuracy did not improve from 0.69518\n",
      "6248/6248 [==============================] - 1762s 282ms/step - loss: 0.5309 - accuracy: 0.7182 - val_loss: 0.5546 - val_accuracy: 0.6910\n",
      "Epoch 5/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.7438\n",
      "Epoch 00005: val_accuracy improved from 0.69518 to 0.69622, saving model to model.h5\n",
      "6248/6248 [==============================] - 1767s 283ms/step - loss: 0.4977 - accuracy: 0.7438 - val_loss: 0.5561 - val_accuracy: 0.6962\n",
      "Epoch 6/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.7729\n",
      "Epoch 00006: val_accuracy did not improve from 0.69622\n",
      "6248/6248 [==============================] - 1760s 282ms/step - loss: 0.4547 - accuracy: 0.7729 - val_loss: 0.5992 - val_accuracy: 0.6910\n",
      "Epoch 7/20\n",
      "6248/6248 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8016\n",
      "Epoch 00007: val_accuracy did not improve from 0.69622\n",
      "6248/6248 [==============================] - 1758s 281ms/step - loss: 0.4077 - accuracy: 0.8016 - val_loss: 0.6667 - val_accuracy: 0.6777\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "\n",
    "train_sh = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=8,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 14684.663488,
   "end_time": "2021-11-12T15:29:33.973608",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-12T11:24:49.310120",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
